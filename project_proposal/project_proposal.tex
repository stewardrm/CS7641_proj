\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifcvprfinal\pagestyle{empty}\fi
\begin{document}

%%%%%%%%% TITLE
\title{Team Rotten Tomatoes}

\author{Greta Sharoyan\\
Georgia Institute of Technology\\
{\tt\small gsharoya@gatech.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Peng Chun\\
Georgia Institute of Technology\\
{\tt\small pchun9@gatech.edu}\\
\and
Amari Farnaz\\
Georgia Institute of Technology\\
{\tt\small farnaz\_amiri@gatech.edu}
\and
Robert Steward\\
Georgia Institute of Technology\\
{\tt\small rsteward7@gatech.edu}
}

\maketitle
%\thispagestyle{empty}



%%%%%%%%% BODY TEXT
\section{What we will do}
We will develop a content based movie recommender system using Bidirectional Encoder Representations from Transformers (Bert) embeddings.    A key advantage of BERT is that it has been trained a very large corpus of text.  Additionally, BERT has the advantage that it captures context of words achieved by its use of a bi-directional transformation vector.  The data set of interest will contain movie titles along with pertinent information such as popularity plot description.  A user may then enter a set of one or more key words such as “comedy, rated PG” from which our Deep Learning model will then output several suggested movie recommendations ranked by a metric of similarity.

\section{Resources}

Research into recommender systems in general and movie recommendations in particular is not new as many companies are highly monetarily incentivized to give its users pertinent options.  Yet at the same time, these models are constantly evolving as market pressures force company strategies to evolve in an ever more competitive environment for market share. "BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformers" by Pengjie Ren et al. is one such current research paper that provides user recommendations in a contextual sequential setting.  Furthermore, introduction tutorials can also be found on the web both here “https://towardsdatascience.com/creating-a-hybrid-content-collaborative-movie-recommender-using-deep-learning-cc8b431618af” and here “https://medium.com/analytics-vidhya/recommendation-system-using-bert-embeddings-1d8de5fc3c56”.


\section{Datasets}

While at this stage in the project, we have yet to begin implementation and formally settle on a project data source, several possible resources are available.  For example Kaggle has dataset available here ” https://medium.com/analytics-vidhya/recommendation-system-using-bert-embeddings-1d8de5fc3c56” which depicts the top trending YoutTube videos of 20201.  Another viable data set for us may be found here MovieLenhttps://grouplens.org/datasets/movielens/s | GroupLens which contains over 25M different ratings for modern movies.  Several other applicable data sets also are available at “NetFlix Prize”, “IMDB”, “Flixter”.  We explore all these options to see which of these data set option are the most amenable for us to achieve are stated purpose above within the project constraints of the course.

\end{document}
